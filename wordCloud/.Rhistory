q = NULL, q.arg = NULL, ...)
## S3 method for class 'fast99'
tell(x, y = NULL, ...)
## S3 method for class 'fast99'
print(x, ...)
## S3 method for class 'fast99'
plot(x, ylim = c(0, 1), ...)
library(sensitivity)
install.packages("sensitivity")
library(sensitivity)
install.packages("sensitivity")
library(sensitivity)
library(sensitivity)
library("ggplot2", lib.loc="~/R/win-library/3.4")
install.packages("sensitivity")
library(ROCR)
library(ROCR)
mydata <- read.csv(file="C:/Users/amanpreet_singh/Documents/practice/Sensitivity Analysis/actual.csv", header=TRUE, sep=",")
mydata
pred <- prediction(mydata$ip1,mydata$ip2)
typeof(mydata)
mydata
dat1 <- data.frame(val=c(mydata[ip1]),label=c(mydata[ip1]))
dat1 <- data.frame(val=c(mydata['ip1']),label=c(mydata[ip1]))
dat1 <- data.frame(val=c(mydata['ip1']),label=c(mydata[ip1]))
mydata[ip1]
mydata['ip1']
dat1 <- data.frame(val=c(mydata['ip1']),label=c(mydata[ip2]))
dat1 <- data.frame(val=c(mydata['ip1']),label=c(mydata['ip2']))
pred <- prediction(dat1$val,dat1$label)
perf = performance(pred,measure="tpr",x.measure="fpr")
library(sensitivity)
install.packages("sensitivity")
install.packages("sensitivity")
mydata <- read.csv(file="C:/Users/amanpreet_singh/Documents/practice/Sensitivity Analysis/actual.csv", header=TRUE, sep=",")
library(ROCR)
library(ROCR)
mydata <- read.csv(file="C:/Users/amanpreet_singh/Documents/practice/Sensitivity Analysis/actual.csv", header=TRUE, sep=",")
mydata['ip1']
dat1 <- data.frame(val=c(mydata['ip1']),label=c(mydata['ip2']))
pred <- prediction(dat1$val,dat1$label)
mydata[0]
mydata[1]
cf <- mydata[1]
cf
cf[0]
cf[1]
cf[2]
cf <- mydata[2]
cf[2]
cf[1]
install.packages("sensitivity")
library(sensitivity)
as.data.frame.fast99 <- function(x, ...) {
if (!is.null(x$y)) {
S <- data.frame(X=colnames(x$X), x$D1/x$V, 1 - x$Dt/x$V)
colnames(S)[-1] <- c("first.order", "total.order")
S
}
}
dd<-as.data.frame(x)
dd<-as.data.frame.fast99(x)
x <- fast99(model = ishigami.fun, factors = 3, n = 1000,
q = "qunif", q.arg = list(min = -pi, max = pi))
print(x)
as.data.frame.fast99 <- function(x, ...) {
if (!is.null(x$y)) {
S <- data.frame(X=colnames(x$X), x$D1/x$V, 1 - x$Dt/x$V)
colnames(S)[-1] <- c("first.order", "total.order")
S
}
}
dd<-as.data.frame.fast99(x)
library(ggplot2)
ggplot(dd, aes(x=X)) +
geom_point(aes(y=first.order, color="first")) +
geom_point(aes(y=total.order, color="total")) +
scale_color_manual(values=c(first="red",total="blue"), name="order")
x <- fast99(model = ishigami.fun, factors = 4, n = 1000,
q = "qunif", q.arg = list(min = -pi, max = pi))
print(x)
as.data.frame.fast99 <- function(x, ...) {
if (!is.null(x$y)) {
S <- data.frame(X=colnames(x$X), x$D1/x$V, 1 - x$Dt/x$V)
colnames(S)[-1] <- c("first.order", "total.order")
S
}
}
dd<-as.data.frame.fast99(x)
library(ggplot2)
ggplot(dd, aes(x=X)) +
geom_point(aes(y=first.order, color="first")) +
geom_point(aes(y=total.order, color="total")) +
scale_color_manual(values=c(first="red",total="blue"), name="order")
udacious <- c("Chris Saden", "Lauren Castellano",
"Sarah Spikes","Dean Eckles",
"Andy Brown", "Moira Burke",
"Kunal Chawla")
numbers <- c(1:10)
numbers
numbers <- c(numbers, 11:20)
numbers
udacious <- c("Chris Saden", "Lauren Castellano",
"Sarah Spikes","Dean Eckles",
"Andy Brown", "Moira Burke",
"Kunal Chawla", "Amanpreet Singh")
mystery = nchar(udacious)
mystery
mystery == 11
udacious[mystery == 11]
data(mtcars)
names(mtcars)
?mtcars
mtcars
str(mtcars)
dim(mtcars)
?row.names
row.names(mtcars) <- c(1:32)
mtcars
row.names(mtcars) <- c(1:33)
row.names(mtcars) <- c(1:32)
mtcars
data(mtcars)
head(mtcars, 10)
head(mtcars)
tail(mtcars, 3)
mtcars$mpg
mtcars$hp
mtcars$wt
mean(mtcars$mpg)
install.packages(swirl)
install.packages("swirl")
install.packages("swirl")
getwd()
getwd()
setwd('C:/Users/amanpreet_singh/Documents/Data Analysis with R/lesson4_problem_set_explore 1 variable')
knitr::opts_chunk$set(echo = TRUE)
csv_data_hiv <- read.csv("data.csv")
names(csv_data_hiv)
plot(csv_data_hiv)
ggplot(aes(x = 1979), data = csv_data_hiv) +
geom_histogram()
library(ggplot2)
ggplot(aes(x = 1979), data = csv_data_hiv) +
geom_histogram()
ggplot(aes(x = 1979), data = csv_data_hiv) +
geom_histogram() + scale_x_continuous(breaks = 1:30)
ggplot(aes(x = 1979), data = csv_data_hiv) +
geom_histogram() +
scale_x_continuous(limits = c(1979, 2011), breaks = seq(1979, 2011, 20))
ggplot(aes(x = 1979), data = csv_data_hiv) +
geom_histogram(binwidth = 10) +
scale_x_continuous(limits = c(1979, 2011), breaks = seq(1979, 2011, 20))
ggplot(aes(x = 1979), data = csv_data_hiv) +
geom_histogram(binwidth = 1) +
scale_x_continuous(limits = c(1979, 2011), breaks = seq(1979, 2011, 20))
ggplot(aes(x = 1979), data = csv_data_hiv) +
geom_histogram() +
scale_x_continuous(limits = c(1979, 2011))
ggplot(aes(x = 1979), data = csv_data_hiv) +
geom_histogram() +
scale_x_continuous(limits = c(1950, 2011))
ggplot(aes(x = 1979), data = csv_data_hiv) +
geom_histogram() +
scale_x_continuous(limits = c(1970, 2011))
rm(csv_data_hiv)
employment_excel_data <- read.xlsx("data_15-24 employment_rate.xls", 1)
employment_excel_data <- read.xlsx("data_15-24 employment_rate.xlsx", 1)
install.packages("xlsx")
employment_excel_data <- read.xlsx("data_15-24 employment_rate.xlsx", 1)
library("xlsx")
employment_excel_data <- read.xlsx("data_15-24 employment_rate.xlsx", 1)
names(employment_excel_data)
ggplot(aes(x = 1991, y = 1992), data = employment_excel_data) +
geom_freqpoly()
ggplot(aes(x = 1991), data = employment_excel_data) +
geom_freqpoly()
ggplot(aes(x = 1991), data = employment_excel_data) +
geom_freqpoly(y = 1992)
ggplot(aes(x = 1991, y = 1992), data = employment_excel_data) +
geom_freqpoly()
ggplot(aes(x = 1991, y = 1992), data = employment_excel_data) +
geom_point()
ggplot(aes(x = X1991, y = X1992), data = employment_excel_data) +
geom_point()
ggplot(aes(x = X1991, y = X2007), data = employment_excel_data) +
geom_point()
ggplot(aes(x = X1991, y = X2007), data = employment_excel_data) +
geom_freqpoly()
ggplot(aes(x = X1991, y = X2007), data = employment_excel_data) +
geom_histogram()
ggplot(aes(x = X1991, y = X2007), data = employment_excel_data) +
geom_point()
ggplot(aes(x = X1991, y = X2007), data = employment_excel_data) +
geom_point() +
xlab("Employment % during year 1991") +
ylab("Employment % during year 2007")
ggplot(aes(x = X1991, y = X2007), data = employment_excel_data) +
geom_point() +
xlab("Employment % during year 1991") +
ylab("Employment % during year 2007") +
geom_smooth(method='lm')
summary(employment_excel_data$X1991)
summary(employment_excel_data$X2007)
summary(employment_excel_data$X1991)
summary(employment_excel_data$X2007)
summary(employment_excel_data$X2007)
ggplot(aes(x = summary(X1991), y = summary(X2007)), data = employment_excel_data) +
geom_point() +
xlab("Employment % during year 1991") +
ylab("Employment % during year 2007") +
geom_smooth(method='lm')
ggplot(aes(x = summary(X1991), y = summary(X2007)), data = subset(x1991,employment_excel_data)) +
geom_point() +
xlab("Employment % during year 1991") +
ylab("Employment % during year 2007") +
geom_smooth(method='lm')
ggplot(aes(x = summary(employment_excel_data$X1991), y = employment_excel_data$summary(X2007)), data = subset(x1991,employment_excel_data)) +
geom_point() +
xlab("Employment % during year 1991") +
ylab("Employment % during year 2007") +
geom_smooth(method='lm')
ggplot(aes(x = summary(employment_excel_data$X1991), y = employment_excel_data$summary(X2007)), data = subset(X1991,employment_excel_data)) +
geom_point() +
xlab("Employment % during year 1991") +
ylab("Employment % during year 2007") +
geom_smooth(method='lm')
,employment_excel_data)) +
ggplot(aes(x = summary(employment_excel_data$X1991), y = employment_excel_data$summary(X2007)), data = subset("X1991",employment_excel_data)) +
geom_point() +
xlab("Employment % during year 1991") +
ylab("Employment % during year 2007") +
geom_smooth(method='lm')
ggplot(aes(x = summary(employment_excel_data$X1991), y = employment_excel_data$summary(X2007)), data = employment_excel_data[c(X1991, X2007)]) +
geom_point() +
xlab("Employment % during year 1991") +
ylab("Employment % during year 2007") +
geom_smooth(method='lm')
ggplot(aes(x = summary(employment_excel_data$X1991), y = employment_excel_data$summary(X2007)), data = employment_excel_data[c('X1991', 'X2007')]) +
geom_point() +
xlab("Employment % during year 1991") +
ylab("Employment % during year 2007") +
geom_smooth(method='lm')
ggplot(aes(x = summary(employment_excel_data$X1991),
y = employment_excel_data$summary(X2007)),
data = employment_excel_data[c(employment_excel_data$X1991, employment_excel_data$X2007)]) +
geom_point() +
xlab("Employment % during year 1991") +
ylab("Employment % during year 2007") +
geom_smooth(method='lm')
ggplot(aes(x = summary(employment_excel_data$X1991),
y = employment_excel_data$summary(X2007)),
data = c(employment_excel_data$X1991, employment_excel_data$X2007)) +
geom_point() +
xlab("Employment % during year 1991") +
ylab("Employment % during year 2007") +
geom_smooth(method='lm')
by(employment_excel_data$X1991, employment_excel_data$X2007, summary)
cor.test(employment_excel_data$X1991, employment_excel_data$X2007, method = 'pearson')
cor.test(employment_excel_data$X1991, employment_excel_data$X2007, method = 'pearson')
ggsave('GapminderExersizeimage1.png')
ggplot(aes(x = X1991, y = X2007), data = employment_excel_data) +
geom_point() +
xlab("Employment % during year 1991") +
ylab("Employment % during year 2007")
ggsave('GapminderExersizeimage1.png')
ggplot(aes(x = X1991, y = X2007), data = employment_excel_data) +
geom_point() +
xlab("Employment % during year 1991") +
ylab("Employment % during year 2007") +
geom_smooth(method='lm')
ggsave('GapminderExersizeimage2.png')
ggplot(aes(X1991,X2007,color = Total.15.24.employment.to.population....),data = subset(employment_excel_data,
!is.na(Total.15.24.employment.to.population....)&
!is.na(2007)& !is.na(X1991)))+
geom_point(alpha = 0.05)+
geom_smooth()+
xlab("Percent of Land Area")+
ylab("Export Percent of GDP")
ggplot(aes(X1991,X2007),data = subset(employment_excel_data)&
!is.na(2007)& !is.na(X1991))+
geom_point(alpha = 0.05)+
geom_smooth()+
xlab("Percent of Land Area")+
ylab("Export Percent of GDP")
ggplot(aes(X1991,X2007,color = Total.15.24.employment.to.population....),data = subset(employment_excel_data,
!is.na(Total.15.24.employment.to.population....)&
!is.na(2007)& !is.na(X1991)))+
geom_point(alpha = 0.05)+
geom_smooth()+
xlab("Percent of Land Area")+
ylab("Export Percent of GDP")
dates <- as.Date(read.csv("birthdaysExample.csv"))
dates <- read.csv("birthdaysExample.csv")
names(dates)
as.Date(dates)
getwd()
setwd('C:/Users/amanpreet_singh/Documents/Data Analysis with R/wordCloud')
getwd()
knitr::opts_chunk$set(echo = TRUE)
library(tm)
install.packages(tm)
install.packages("tm")
library(tm)
library(tm)
library(SnowballC)
install.packages("Snowballc")
install.packages("SnowballC")
library(SnowballC)
library(wordcloud)
install.packages("wordcloud")
library(wordcloud)
library(wordcloud)
csv_data = read.csv("JEOPARDY_CSV.csv")
names(csv_data)
rm(dates)
rm(employment_excel_data)
csv_data <- read.csv("JEOPARDY_CSV.csv")
names(csv_data)
data_corpus <- Corpus(VectorSource(csv_data$Question))
data_corpus
data_corpus <- tm_map(data_corpus, PlainTextDocument)
data_corpus <- tm_map(data_corpus, removePunctuation)
data_corpus <- tm_map(data_corpus, removeWords, stopwords('english'))
data_corpus <- tm_map(data_corpus, stemDocument)
data_corpus <- tm_map(data_corpus, stemDocument)
wordcloud(data_corpus, max.words = 100, random.order = FALSE)
wordcloud(data_corpus, max.words = 100, random.order = FALSE)
m <- as.matrix(data_corpus)
dtm <- TermDocumentMatrix(data_corpus)
inspect(data_corpus)
data_corpus <- Corpus(VectorSource(csv_data$Question))
inspect(data_corpus)
toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
data_corpus <- tm_map(data_corpus, toSpace, "/")
data_corpus <- tm_map(data_corpus, toSpace, "@")
data_corpus <- tm_map(data_corpus, toSpace, "\\|")
data_corpus <- Corpus(VectorSource(csv_data$Question))
inspect(data_corpus)
data_corpus <- tm_map(data_corpus, PlainTextDocument)
toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
data_corpus <- tm_map(data_corpus, toSpace, "/")
data_corpus <- tm_map(data_corpus, toSpace, "@")
data_corpus <- tm_map(data_corpus, toSpace, "\\|")
data_corpus <- tm_map(data_corpus, content_transformer(tolower))
data_corpus <- tm_map(data_corpus, removeNumbers)
data_corpus <- tm_map(data_corpus, removeWords, stopwords('english'))
data_corpus <- tm_map(data_corpus, removePunctuation)
data_corpus <- tm_map(data_corpus, stripWhitespace)
data_corpus <- tm_map(data_corpus, stemDocument)
dtm <- TermDocumentMatrix(data_corpus)
m <- as.matrix(dtm)
m <- as.matrix(dtm)
text_data <- readLines("textfile.txt")
data_corpus <- Corpus(VectorSource(text_data))
inspect(data_corpus)
toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
data_corpus <- tm_map(data_corpus, toSpace, "/")
data_corpus <- tm_map(data_corpus, toSpace, "@")
data_corpus <- tm_map(data_corpus, toSpace, "\\|")
data_corpus <- tm_map(data_corpus, content_transformer(tolower))
data_corpus <- tm_map(data_corpus, removeNumbers)
data_corpus <- tm_map(data_corpus, removeWords, stopwords('english'))
data_corpus <- tm_map(data_corpus, removePunctuation)
data_corpus <- tm_map(data_corpus, stripWhitespace)
data_corpus <- tm_map(data_corpus, stemDocument)
dtm <- TermDocumentMatrix(data_corpus)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 10)
head(d, 10)
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=200, random.order=FALSE,
colors=brewer.pal(8, "Dark2"))
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=100, random.order=FALSE,
colors=brewer.pal(8, "Dark2"))
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=150, random.order=FALSE,
colors=brewer.pal(8, "Dark2"))
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=125, random.order=FALSE,
colors=brewer.pal(8, "Dark2"))
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=100, random.order=FALSE,
colors=brewer.pal(8, "Dark2"))
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=100, random.order=FALSE,
colors=brewer.pal(8, "Dark2"))
library(tm)
library(SnowballC)
library(wordcloud)
text_data <- readLines("textfile.txt")
data_corpus <- Corpus(VectorSource(text_data))
inspect(data_corpus)
toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
data_corpus <- tm_map(data_corpus, toSpace, "/")
data_corpus <- tm_map(data_corpus, toSpace, "@")
data_corpus <- tm_map(data_corpus, toSpace, "\\|")
data_corpus <- tm_map(data_corpus, content_transformer(tolower))
data_corpus <- tm_map(data_corpus, removeNumbers)
data_corpus <- tm_map(data_corpus, removeWords, stopwords('english'))
data_corpus <- tm_map(data_corpus, removePunctuation)
data_corpus <- tm_map(data_corpus, stripWhitespace)
data_corpus <- tm_map(data_corpus, stemDocument)
dtm <- TermDocumentMatrix(data_corpus)
dtm
type(dtm)
m <- as.matrix(dtm)
m
v <- sort(rowSums(m),decreasing=TRUE)
v
d <- data.frame(word = names(v),freq=v)
d
head(d, 10)
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=100, random.order=FALSE,
colors=brewer.pal(8, "Dark2"))
text_data <- readLines("textfile1.txt")
data_corpus <- Corpus(VectorSource(text_data))
inspect(data_corpus)
toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
data_corpus <- tm_map(data_corpus, toSpace, "/")
data_corpus <- tm_map(data_corpus, toSpace, "@")
data_corpus <- tm_map(data_corpus, toSpace, "\\|")
data_corpus <- tm_map(data_corpus, content_transformer(tolower))
data_corpus <- tm_map(data_corpus, removeNumbers)
data_corpus <- tm_map(data_corpus, removeWords, stopwords('english'))
data_corpus <- tm_map(data_corpus, removePunctuation)
data_corpus <- tm_map(data_corpus, stripWhitespace)
data_corpus <- tm_map(data_corpus, stemDocument)
dtm <- TermDocumentMatrix(data_corpus)
m <- as.matrix(dtm)
m
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 10)
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=100, random.order=FALSE,
colors=brewer.pal(8, "Dark2"))
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=200, random.order=FALSE,
colors=brewer.pal(8, "Dark2"))
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=300, random.order=FALSE,
colors=brewer.pal(8, "Dark2"))
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=400, random.order=FALSE,
colors=brewer.pal(8, "Dark2"))
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=500, random.order=FALSE,
colors=brewer.pal(8, "Dark2"))
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=600, random.order=FALSE,
colors=brewer.pal(8, "Dark2"))
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=700, random.order=FALSE,
colors=brewer.pal(8, "Dark2"))
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=800, random.order=FALSE,
colors=brewer.pal(8, "Dark2"))
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=900, random.order=FALSE,
colors=brewer.pal(8, "Dark2"))
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=1000, random.order=FALSE,
colors=brewer.pal(8, "Dark2"))
inspect(data_corpus)
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=1000, random.order=FALSE,
colors=brewer.pal(8, "Dark2"))
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=100, random.order=FALSE,
colors=brewer.pal(8, "Dark2"))
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=1, random.order=FALSE,
colors=brewer.pal(8, "Dark2"))
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=1000, random.order=FALSE,
colors=brewer.pal(8, "Dark2"))
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=10000, random.order=FALSE,
colors=brewer.pal(8, "Dark2"))
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=1000, random.order=FALSE,
colors=brewer.pal(8, "Dark2"))
library(tm)
library(SnowballC)
library(wordcloud)
text_data <- readLines("textfile.txt")
data_corpus <- Corpus(VectorSource(text_data))
toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
data_corpus <- tm_map(data_corpus, toSpace, "/")
data_corpus <- tm_map(data_corpus, toSpace, "@")
data_corpus <- tm_map(data_corpus, toSpace, "\\|")
data_corpus <- tm_map(data_corpus, content_transformer(tolower))
data_corpus <- tm_map(data_corpus, removeNumbers)
data_corpus <- tm_map(data_corpus, removeWords, stopwords('english'))
data_corpus <- tm_map(data_corpus, removePunctuation)
data_corpus <- tm_map(data_corpus, stripWhitespace)
data_corpus <- tm_map(data_corpus, stemDocument)
dtm <- TermDocumentMatrix(data_corpus)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=1000, random.order=FALSE,
colors=brewer.pal(8, "Dark2"))
